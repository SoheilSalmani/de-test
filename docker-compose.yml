version: "3.8"

# Airflow environment variables
x-environment: &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW__WEBSERVER__RBAC=False
  - TRX_TOKEN=${TRX_TOKEN}

# Airflow image
x-airflow-image: &airflow_image apache/airflow:2.2.4-python3.9

services:
  # PostgreSQL database backend for Airflow
  postgres:
    image: postgres:13-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  # Initialize Airflow and create an admin user
  init:
    image: *airflow_image
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    command: -c 'airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.org'

  # Airflow webserver
  webserver:
    image: *airflow_image
    restart: always
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    volumes:
      - airflow_logs:/opt/airflow/logs
    environment: *airflow_environment
    command: webserver

  # Airflow scheduler
  scheduler:
    image: *airflow_image
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    environment: *airflow_environment
    command: scheduler

volumes:
  # Docker volume to store all logs emitted by Airflow
  airflow_logs:
